name: GAN
lat_dim: 128
norm: batch
spectral_norm: false
self_attention: false
activation: elu
leak: 0.2

generator:
  channels: [1024, 512, 256, 128, 3]
  init_size: 4
  activation: elu
  norm: batch
  attention_layers: []

discriminator: 
  activation: elu
  norm: none
  spectral_norm: false
  channels: [3, 64, 128, 256]