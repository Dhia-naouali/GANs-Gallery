lat_dim: 128
norm: batch
spectral_norm: true
self_attention: false
activation: elu
leak: 0.1

generator:
  hidden_dim: 256
  depth: 5
  attention_layers: 

discriminator: 
  hidden_eim: 256
  depth: 5
