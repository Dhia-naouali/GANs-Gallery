lat_dim: 128
norm: batch
spectral_norm: true
self_attention: false
activation: elu
leak: 0.1

generator:
  hidden_dim: 128
  depth: 6
  attention_layers: 

discriminator: 
  hidden_dim: 128
  depth: 6
