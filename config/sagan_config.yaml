defaults:
  - data: afhq
  - scheduler: warm_up_linear
  - wandb: default
  - _self_

model:
  name: GAN
  lat_dim: 128
  norm: batch
  spectral_norm: true
  self_attention: true
  activation: elu
  leak: 0.2

  generator:
    channels: [1024, 512, 256, 128, 64]
    init_size: 4
    activation: elu
    norm: batch
    attention_layers: [2]   # Self-attention after 3rd upsample block
    upsample: [deconv, deconv, deconv, interpolation, interpolation]

  discriminator:
    activation: elu
    norm: none
    spectral_norm: true
    channels: [3, 64, 128, 256, 512, 1024]
    attention_layers: [3]   # Self-attention in 4th downsample block

optimizer:
  name: adam
  G_lr: 4e-4
  D_lr: 1e-4
  beta1: 0.5
  beta2: 0.999

training:
  epochs: 160
  batch_size: 32
  image_size: 256
  compile: true
  save_every: 20
  sample_every: 10
  evaluate_every: 4
  n_critic: 1

loss:
  criterion: hinge
  grad_penalty: 0
  r1_penalty: 0
  path_length_penalty: 0

seed: 12

ADA:
  use_ADA: true

log_dir: ./logs
checkpoint_dir: ./checkpoints
sample_dir: ./samples
